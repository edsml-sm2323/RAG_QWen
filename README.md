# RAG_QWen
基于大语言模型LLM构建一个问答系统，问答内容涉及基金/股票/债券/招股书等不同数据来源

## 初步准备
竞赛的主要流程为使用RAG结合.db与.pdf数据构建一个基于大语言模型LLM的问答系统。

首先，我将只考虑将大语言模型与pdf数据进行结合，获得答案。之后再做NL2SQL的任务。

### PDF文件转txt文件
对于PDF数据，首先需要将其转化为.txt文件，以使得LLM更好的理解。竞赛题中给了转化好的txt文件，但是转化效果一般，且pdf文件中的表格数据没有被很好地抓取出来。于是，在这一步我首先尝试使用pdfplumber，这样能在保留pdf内容的情况下更好的获取pdf文件中的表格数据。还有很多其他的方式，我将后续尝试pdfminer、gptpdf、RAGFlow等一系列工具。`（如何查看并比较不同方法转化的效果？）`

问题一：如何更好的读取PDF中的数据

问题二：如何将文件以公司名进行命名 （方便后续的检索）

问题三：如何抓取PDF中的表格数据

问题四：模块化，方便后续修改

pdf2txt文件夹中提供了pdfplumber的使用过程，以及使用LLM分析并抓取文件中公司名称并且修改文件名的过程。
处理过后的文件可以从下方链接下载。
https://drive.google.com/drive/folders/1kiMREC8LdFsgJt6VpJk6cVvuU-LwQhH8?usp=drive_link

### 文档分块, 检索与重排
现在已经获得了pdf文件对应的txt文件，传统的RAG流程中接下来应该做：`分块`, `embedding`, `向量数据库`。

这里先借鉴博主`linmoo1986`的做法，具体操作如下:
本案例是一个金融招股书的检索，每一份招股书都是对应一个公司，而question.json中对于检索招股书都会涉及公司名称，因此该部分的设计可以利用该特性进行设计

对pdf文档进行解析为txt，并以对应公司名称进行存储

分块，对文档进行2个层次分块，先进行较大长度分块，然后通过将较大长度的分块进行细分块，这样公司-大分块-小分块的映射关系，在检索的时候，可以通过公司进行匹配，在embedding中，可以通过小分块匹配后，找到大分块，这样增加上下文内容，从而提高召回率

通过问题与公司之间的匹配度，获得公司名称

通过双链路检索（稀疏BM25检索和密集embedding相似度检索），增加检索结果的准确率

通过重排，将2种查询结果进行重排，增加检索结果的准确率


### 结果生成
阅读json文件，总计1000条问题，需要依次读取生成答案后，并将id, 问题与答案组合起来保存为一个jsonl文件。

使用OpenAI提供的API，并使用A100进行推理，但处理速度仍然很慢。(解决办法？）



